"""
Node for performing data extraction from the paper text.

This node constructs a combined prompt consisting of a system prompt and a
user prompt and passes it to the ``extraction_extractor`` from
:mod:`knowmat2.extractors`.  The system prompt is generated by
:func:`knowmat2.prompt_generator.generate_system_prompt` and can be
modified by the subâ€‘field detection and evaluation agents via
``state['updated_prompt']``.  The user prompt wraps the paper text.

The extractor returns a Pydantic model representing a list of
``CompositionProperties`` which is converted to a native Python ``dict``
before being stored on the state under ``latest_extracted_data``.
"""

import json
from typing import Dict, Any
from knowmat.extractors import extraction_extractor, CompositionList
from knowmat.prompt_generator import generate_system_prompt, generate_user_prompt
from knowmat.states import KnowMatState


def extract_data(state: KnowMatState) -> Dict[str, Any]:
    """Perform the main LLM extraction and return the structured data.

    Parameters
    ----------
    state: KnowMatState
        The current workflow state.  Must include ``paper_text``.  May
        include ``sub_field`` and ``updated_prompt`` which will be
        incorporated into the system prompt.

    Returns
    -------
    dict
        Updates containing ``latest_extracted_data``.
    """
    paper_text = state.get("paper_text", "")
    sub_field = state.get("sub_field")
    prompt_updates = state.get("updated_prompt", "").strip()
    # Build the system prompt, injecting the sub_field if available
    system_prompt = generate_system_prompt(sub_field=sub_field)
    if prompt_updates:
        system_prompt = system_prompt.strip() + "\n\n" + prompt_updates
    # Build the user prompt
    user_prompt = generate_user_prompt(paper_text)
    # Compose the final prompt.  We join the system and user prompts with a
    # separator to indicate two distinct chat messages.  TrustCall handles
    # message formatting internally.
    full_prompt = system_prompt + "\n\n" + user_prompt + "\n\n" + (
        "Provide your response using the tool."
    )
    # Invoke the extraction extractor
    result = extraction_extractor.invoke(full_prompt)
    response = result.get("responses", [None])[0]
    if response is None:
        # If nothing returned, leave latest_extracted_data unchanged
        return {}
    # Convert to dict; response is a CompositionList instance when using Pydantic
    if isinstance(response, CompositionList):
        extracted_dict = json.loads(response.model_dump_json())
    else:
        # Already a dict
        extracted_dict = response
    return {"latest_extracted_data": extracted_dict}